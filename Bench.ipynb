{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wthsDgHkmA8O"
   },
   "source": [
    "# 0. Импорт библиотек и модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCBnDAWqZSpU"
   },
   "outputs": [],
   "source": [
    "!pip install datasets >> None\n",
    "!pip install transformers >> None\n",
    "!pip install sentence-transformers >> None\n",
    "!pip install langdetect >> None\n",
    "!pip install torch >> None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "PdD1RxZKb3zX"
   },
   "outputs": [],
   "source": [
    "# os\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "from collections import Counter\n",
    "import warnings\n",
    "from random import randint\n",
    "\n",
    "# transfromers & models\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer, pipeline, AutoModelForCausalLM\n",
    "from transformers import BertForSequenceClassification, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from langdetect import detect\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from transformers import XLNetLMHeadModel, XLNetTokenizer\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXSgBn2fb7OT"
   },
   "source": [
    "# 1. Загрузка данных и токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PfOuYM1XpvdF"
   },
   "outputs": [],
   "source": [
    "dataset_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AiYxWPcEdSqh"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_path)\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "38c1e53e3b0e42668947766cf0eee570",
      "0a8aea3ff4184625a888f1a9febf0f63",
      "ab9e64a10650489b9e5eda9c82ad3f17",
      "d403a3d1bf74414c80578f63ad21e829",
      "1aed3696c910402db7d464076a76122a",
      "e9772f34a9eb49bf8d480f552dd5b6a9",
      "5426f575c0ee423b983cf7576c240e99",
      "98f3d4a969324822b4fc02c9aaeef62d",
      "65a67bbf191244c4bbf469137264f568",
      "dad6dc32513240b1a1ce6b9cd06fbad0",
      "e93b497e72004ec8b57de04d1f57e973",
      "4ebd49503b3343208e95d5590ef8b7ff",
      "972c78cc222547b9b1b41a1f62fbd7a6",
      "b1ab56a9408e4eacb2cf934df1e652e8",
      "235143f2bfe543c2b35e1b984d464641",
      "4e2e2c80878247b1a6271a5d0faafd69",
      "87f48725d967476d91a2ef48536a9db5",
      "4c7bca3e01b64db681e0aba09af49dfa",
      "caca5ae8f0bb4e288bcb5d715a36017b",
      "51779fe3794a44cf989626caf328b0e5",
      "b62299855e2c4edc86ac4a0e807bbd5c",
      "bb81d06bb0f44869bc91dd3e46ede356",
      "acdb03136a814e4190dc816c4d1c21a9",
      "7663b2827f6247a6a843369038ba8674",
      "e871f9f182f044eaa6109ac105b1c530",
      "5f56bb0ce8464d158ee2ca5fc703f595",
      "26cfef4040d94bca98ceb3319703d10b",
      "51ab05a4a32c41eca1c1a9067e13da7b",
      "ea67fb7660da46ab8af9e15f6a62857c",
      "247d387e0bf24feab2db3fc00e58823a",
      "1a511d16128a46f7b5e165c6dd4c9672",
      "a94eefcba71c40069b82b2ec7fb0c189",
      "1dab5187637d4ef1be7358cb54d735af",
      "dba56decc39a4408883ef34d2b09e5eb",
      "4a5dd08f24c14a5db2d807d3796b5a54",
      "da0543e63f0b465ea5b9d32fb64fad0f",
      "3677af40f07544dea7bc4aeddb0697f2",
      "9df46af2e1a54419833e4e23eb62bcbd",
      "23c47f1e2469494ba1cce4533eb0c39b",
      "de83d7fb030d4b2e8dcfeb4123c74921",
      "543c1173d4eb4c37b598d8bd39583fb4",
      "dbd9427cc5db4ec99783344a388004ea",
      "0e92fb235d4e42849c29bda035dcd54b",
      "2ca5e280ffd34850a4bc203bc861908f",
      "98e0f8297e27486a8e5c46aee16b0fe6",
      "bca1a46684354df7a5361d8bdf10b5b1",
      "9aa61e4715354e22a3585bddc6bc221f",
      "128214ff8f4849c3a498a1dde6fc376a",
      "87f53f7c3c2a4e62810fbf771f56eb63",
      "41dca871c01842288fd6e81e5549480a",
      "39b86825e3114eed83566529874e1a16",
      "85c9c15fa379475886f90d6441019830",
      "d7c0ecfdfc2b4a2990612299fb55f15f",
      "d57a833865cb4af8a22b96a3ec23c16f",
      "1ef8e905578b47cb927677efbaeb3ef0",
      "bfc415f3150e41ec8e5dcd46eae39b9a",
      "5f2474cbac734866a8ddb6ae9fec0bbd",
      "51fdc37460aa409c9165e4c3525b6c31",
      "ad90b9fc70b14b6eb41405c894003543",
      "08e4ce8b2c124a16b602a91989055d80",
      "217ccaa44ad94dc49c759baeebdb7f5e",
      "08cf5b19e95e4350a026a451731c77ad",
      "d4c1761908d84a1daf8a02f7dd64297f",
      "196aa01141b24cd89b854d150b60e6b4",
      "c625319e20fb485ab7b5cc5d17450a34",
      "4111395d0cf447dc88fe7ecdac8f679f",
      "effa9305219448228ad3feb7a41f16bd",
      "417ef72774184918898ec9bd27f51876",
      "846089ecece248bb9694e37327522bc7",
      "60799c6ac681401a97242b85853a2050",
      "87a36cffe23e4dd7a2fb5c85eb560134",
      "395320b1aaf14f4cbf1f09fee44a82a5",
      "11dc239daf4c4f739d94cee7d97d361f",
      "89198de733cd4fdeacafbdc051af99fe",
      "9ef380d747b4404fb98780976e207df1",
      "57cd040ec36e402f850288281b779f06",
      "640026e83fbb44d6bff3061572f98b0a",
      "4d0f63b86c2f40e2829389b4e418c98b",
      "492d584c9382405cb358830e251b3b20",
      "6606015c6dd94d349ba4eae633105144",
      "fbc87e65135244ac84ff1d9e087e7653",
      "cfac44347b184705a35166db919a2bad",
      "35ce1ddf23c540c4a586f0fd3d260233",
      "1c409f5ab6a547a78eda24212eab0772",
      "fe402bbf81154b229f58837568de7526",
      "dc7f25687c804cba8fbc386affe7d160",
      "df9141efda0b4f889c91a4593f9ac562",
      "abe34c7805ac4b67a06f927fb3255fd3",
      "87f3a6cfcd5a4205bdbb58c8ffe932be",
      "0bf9b2bfa6a049018b59d7c080901ddb",
      "632e8a5d1835416493141afab48e8ea9",
      "b324158f09aa426d9f6b66ec7615ea48",
      "5d2ff9f6f36841aa8926cd317fe99e27",
      "df5699a43b2d431eb0f523e8372582a4",
      "c5cc5529f02d4744b068e2a139700cbd",
      "92480debb66e41e5b14eac1da4d629dc",
      "1090d8ae2eba4cf1a413140dfd97344c",
      "27908870068c400d95fb63009b969fa4",
      "a75d73d833e94ffbb6974f5b9e280667",
      "219cd6f6a69d4d7caca01cec0248deff",
      "381558de416a4fa19ba5e412e4cf957e",
      "3bf5026d461049b4bc8dd4a61bacdf60",
      "f40dee1507f44f198a9bcae281118bda",
      "5322cf23e80a451bac72aea87a4d5c1a",
      "eb51ff972148450ab864cdb7e1838496",
      "b7cf85789dec4b36a44b7ca815f9cac7",
      "9642ca5cdee14de9b5f79030285d14fc",
      "b6fee4cdf83046379aa9464c5d107db1",
      "0ef8edbaa15941dfb0299b64bed24041",
      "dd6aaa6496434d42b212bdf56aaaf42c",
      "9a2a41664990449aabfabece18d710ef",
      "a80c07e558094df499a787a02098f83e",
      "6300ebbc16c14874aeab6d7c1b862b5d",
      "df5ce8e02bde4df08cb363413bc964db",
      "de45aefc394a431083f4691f8d6e967d",
      "5a27067b79104124952197edc91e8921",
      "e3120c66ddbf42cab2e2a0106843f7cc",
      "6c435c91b147494c876d516d8c200ed1",
      "6e4d2ec607e74f9d990fbaa280a8865f",
      "f2c521067e5941069f8997bcd717be96",
      "c25975e6e80c456280e4729f1a466e29",
      "166c0bbd38ee4a9cbeeba8b3bb6d5106",
      "d1981265f9f5400986ce141eea157869",
      "5e94803563d44e68a275abf158c37bf2",
      "e9dc21eaae1a471899326605c4077903",
      "bf6843d5ee644ca797eb323903a2fdca",
      "86150db6c744411489f6730ecbdce78e",
      "9c71028d6ff94bfaacc5c502a43e20d0",
      "7a0961f4910941ff9ffaaa82ed3a50df",
      "ffab36e235b74905816fa89983ec61d6",
      "191938f3c020445fa20b69df367f7e3c",
      "1b9ea1f905c44e3c88df2de450a8e903",
      "f1c137dc98534758a00732f4cf1d6501",
      "f05feafe01774d1e81036956c379dd69",
      "4cacff49f92e4842ad0693e534be650d",
      "00ccf9604bba4d1a91abd8fd3405cd4c",
      "81fcb1fce1af4e578606ece6a22ee41c",
      "962fd7c78db0411fa93d828dc77535cc",
      "b3c44f1937ce4010aecae5a8dcd80fbf",
      "2ef9933b8e9d4460891cdb8a6e0da355",
      "391493570f2d4789aa625b9d4c59dbd1",
      "949c2470e7674d8b815b614d7c53a3ab",
      "056acac84a054b9b99785a02956c2bdc",
      "4a4407b3a50949f2ba51da341be6c538",
      "c54a0149321e4b9fa2479c7c1cb61f1e",
      "06b45320271744368a459ff807c8851d",
      "5542b442c40b461ebc9d484998f5adfa",
      "94b3e24234c64a2f90487e81eb071b66",
      "c28b90945c124ef08cf30ab741b90bec",
      "3529f6e6c035445db3a26137e74c4a83",
      "1293427b74a64b69ade4958239d3d4b2",
      "8af826176a034bf588a13611dac36f09",
      "df80f4da9fe64e5299aa1e0ea1b1de1c",
      "a6cb9c20d7464a89bb88a73cc35285cb",
      "e4a952395fb04143b6deb91273bf4063",
      "393338a4ae6346fab4f55f858a889abe",
      "0607c5a1d79c488a83f8203d7b52d144",
      "fe248a08c09a40b2a4329fa325d2b601",
      "22be51ef97f948759934945ed5330699",
      "4ca57d90a23a49a1b76302305ebc433b",
      "ce813bf6f5774bb48f954e757d4601f7",
      "c6662b3763ce42089694c66fc7b045fe",
      "dd06ffaac64648afb1baff386e9c8b72",
      "543cc538bc6d4bc089565b9eea4f2fb1",
      "642e90f0e5fc45218e3e0aacc55c57a6",
      "63820485b9a94d2abe8767a388055d9f",
      "93631439513c486086e6fe219ba66f0d",
      "6965d88ef67142f3abc838053e65842d",
      "a448b707ed604f41ac7a47d0e1a08e3f",
      "d9232813531845ed9ff4a9f129f85e4c",
      "15f5c72ae9d54a97b0a816bfb85d1d4b",
      "dbf241af0f0e469ea7c8327ddea91e7d",
      "9c2cbb43c57c4473b4f4b484a43007b4",
      "dc4437a0e2f448aea6c204ae2c6b284e",
      "93e048a1afe2430092903a0d2abcaded",
      "00100c4ebc1f4a84bbe6ec678a6db9e5",
      "c5cea90df4e44d4f89276a958cd41748",
      "af91990316a748f4b2d78d7a0588ebba",
      "d16fdb723313444bb776117dc9da7f68",
      "ee871e7bdeb04267871f6bb05e4e1424",
      "38744c7c8c2f40639284cc5d6b62bae5",
      "cabb27d6812a4dcda4bbe2c5157a7343",
      "726f99929bb740369171dc5c6df8226b",
      "63200960af6b4f4fa48bfb7d17f0df09",
      "93c37b1a1a154576a76bb05be7dd9822",
      "fdf0c79f111549dd86e2a4185aef43b5",
      "dc1fae0b194143eebd6ffb44453a207c",
      "1f636eb2335a4cfa9f546bd652ecedeb",
      "6ed418a91ba64078a5fc5783df8732b3",
      "95aa45302d7f424eae2f3ab07eede08c",
      "feb14f22bf634100bc2643e39c67f283",
      "f7dc254123574d40b7b78f357cfd6cc6",
      "4c383e755af74146a2c4b31de16f3d80",
      "ba83171111c946f69c699137562440b2",
      "91fd7fc549bd4e94a8c9b3130e4e727e",
      "ee15cf319bd147ff8e5cf3bba27b4f06",
      "b4d589364d504b1595c7ccb5a8c4c6e8",
      "b2cd328520584b6da2c4c3c5ff36d1ef",
      "d67e7dd2e9994b7bb370e0e7a1c89bf6",
      "6e41ff54689c47d7821fc8339625d2dc",
      "d16b56d8e9d2496aaea8fbffedc71547",
      "89f8895667b44952982c7e35e12aaa04",
      "b7bfc1f0791e469e870cd14d0112d5b9",
      "e1f64b01129148b7b31a9260eff96c50",
      "d487e80acd1b447ea5790c1878da497a",
      "c9e7e5c628634bfeb6966eaf4e6c7871",
      "faf57adcbee04fe2be30f6f1800991ab",
      "cd45bb6f50974289a814230eb40cc12f",
      "6841a5b5d4ec4e8b89dc1441b101ae5e",
      "fddeb695275642d086c7c809279e7ff6",
      "b8e22b9405fe49fe83d92f7772e1b2d7",
      "442f2dc1041548a7ad1754fb75b8f74f",
      "54aea34fd7be427babd2c9583c60ee9b",
      "f68e11746bc34793befe1d822fdd7d92",
      "8c729634db954faca2f99d7d4fe602d4",
      "1fcc27dfa77e45ba99ec5e2c0d3a6a92",
      "dcba388b2f964c8584c157051c7c0c0d",
      "a364be2aee434ba59d205964f514d000",
      "6ef79f5ec76e4d129d2d5bec76e7403f",
      "db88ff8e934745f9b9b61a013a6f3a27",
      "d1b631e536f94d81a7426471a482ac3f",
      "9799200d89f94c64b6e61638d456d437",
      "5e1ed7dae4cb45e8ae98522b249194c2",
      "453591605b5f4a3f883b01e0c530c935",
      "0f4efcae8fcc43cc988612f5a7784733",
      "6b642af19a2d4c40a645294f33911d3f",
      "8f247e6ec59d4030bdc57b247d98e51d",
      "e62c9459a1394e8b90b9bcdcc8cb93b4",
      "246ef5ce8b09418aab8f957eefdb0eac",
      "579644ed605f4204abe3b3e71b75b36e",
      "a272270506254454a25797720d7f060c",
      "c13123dca2aa4136b5c6b3b2ee5aba20",
      "6441a86f45d042a98f3bde737bb00ad7",
      "dab8cb247d824264abf95fb005639578",
      "e7f46b7b0944410097b58360794c6979",
      "171a2bbc21e04be483372c1f7821e061",
      "6856f64ff61d4b6c9f8fd3a2ee62d3db",
      "91522c03193f4a39bc8f9443c333aaaf",
      "b5e549bc80c342ba9a45e6499753deb1",
      "3a3f02f9a06a418fad60a1efccd5870f",
      "7a2d554ccfb84fb99adc21cf99e01d00",
      "d268fabddb084af695a8e059da3c697f",
      "ad96ee2203364388896cb3852cbfbb45",
      "cafd8e5cb8124fc388603c4f3e982ac6",
      "dfd536d050a148f6a9932d8ea93acc12",
      "f2ca19876fcd411ca76840997653264e",
      "e5f9c3e5795f46afaa0b31041d796327",
      "f12853131a474285af982128e720ec09",
      "88c5b41b1050407b807994fbe0edb5c7",
      "820255ebbc9d45c099357e1749ae5238",
      "4030bfc10237426abce4db3c231bbb59",
      "c67cea3f48804429a023558b1c8288d7",
      "dd2764a30d1c4319816d168531ecc17b",
      "59fe880968564090a7436f48d11ddedc",
      "cc1d0401e1a5412eb92234c695810504",
      "aa424c95531b4bb28e68460e36e05d1e",
      "5ca9452a5c7f4de6ba59c35a23c7a7a9",
      "2a5ad4342caf4790b2ce2dd81d6122a8",
      "ea8d8aad95b848a4ba6423f9ec00e40d",
      "854c4ec1e3fb4697b0612c553d75c46e",
      "f7bb623b1e59483eaaad8bbf994f546f",
      "dd58222bf59d41df8b791df7b7fa6608",
      "2155da60eb2f402f8ba3bad258720676",
      "ce5b1c7ce3ea499e9a22fba5d33298ee",
      "1b5466ae02ea420293a09accd876a169",
      "b885130c875f4dc8ae400c04bf78b43c",
      "97f9eaa4ef8f49e183d074a5320ff6b9",
      "7d620fee5c934428a799a08832479a27",
      "0082dbcc5f064f6186858fd9cb5a98e1",
      "43e229482bb24d9aa33a30b7a6db189c",
      "15bee16c1d3f4094827a1e655e1eb34a",
      "9583059128e142cfb2c02e77a3365691",
      "557355033e134cc8bf6da7a0d1147f73",
      "594520ba0c514396a25626fd761adb2c",
      "e64c8f1b388344788a9ad729ec75d05e",
      "19d02deacbf44c1097e72807077a593c",
      "8a4c8b02bc1941cfae9231966ff6dbef",
      "0fe92c7bd06e41e9a47f9c20af5cd961",
      "dd9ff014c02c43a5a60a804de9566cd1",
      "8611e74f0a014a3fbc013a38840a3d11",
      "aabbed1297a14042bb27ff53bedd60c8",
      "204169a64c3d44c6818efa9112af1803",
      "690ab469a6b342d19be3412de497c39b",
      "d88cec8198fd4bddbc748683aa093fb4",
      "c74d244dd8784bb2855d8372b6572a21",
      "5ef5562099304fa39597801ab10bc60e",
      "068bae6fb4ff4ae0b1abf37985f072c4",
      "4883021d230940bd81d14f044aca56fd",
      "2dee72ddb7d1439da500c518525df1c8",
      "6edde762744543e0a44cecf77be6196b",
      "7b34b457d3ff4fb7a834f6dd834fa21a",
      "4bb92597474c4d22b8fe965225710e32",
      "6ff1bde98f3349c696d9d8fb3c060720",
      "86a9e5ce4c7e471c8ce5135dfd2e7345",
      "f06247938dec44ca86852bf41557b5b0",
      "d6946c9f235a4f66a676002740a42ea0",
      "4c7aaf8093e74316a6664884c2e1f4bb",
      "87259df5888e40b193897e91ec1f1cd8",
      "80ae5583e51f4149b54d25dddfe1d532",
      "f75952b590fa4b84bf25fe7268b3c07e",
      "5a78b793436140e1b31d0ef647959819",
      "9fa63df2788242818527ac87824059ba",
      "27cd65d34eae4401b16b6cf2c40a942a",
      "d43824db5e7f4471b505119455dd0e93",
      "5f0d9474312d401f9e02f91019a0de01",
      "23428be5c13f4595820218b472de43a8",
      "8d9311b82bcc45a38a22321b29eaa63c",
      "0baa500128114a7bbf5c9b26b3f930ba",
      "7588d65ce56c4764a4e49fb296e21c78",
      "d44bfaf2d101424ca107de0262688ca0",
      "65d60d42846a42e49f9499e4c3d5a73e",
      "55d0a55317264da1bf0961c7a585cc6a",
      "c8cc6ead03f1419fbac82a122f0a2f01",
      "108c7ea0f9004314932720387ef81aba",
      "c67e5488c40f48469c2d7cd6fb38b3ee",
      "745085c9993b4ffe8e4a9791b55d3d65",
      "2cbc089f2b184b448eb3bc3d79cdf8c9",
      "9cfdc5b50ad5442ea8aa4c797345b894",
      "c19c94633bb54bcf95ccde1aca6a13e1",
      "affb06e5bab64989b9b1a8ba5e0ca950",
      "f6b95ae72b934737bd6736e45cfb3d5c",
      "7e595d247ae044e784fe5de718b4fdcc",
      "14ebcbe9e5794453a2de901ad0f8b9a4",
      "898af9e60a8e436b8d823b5a8347d4b3",
      "044b8d2c28d6418a85684bdb32b80a2f",
      "1db4a4ef933445aeae6d0f3b00e3c511",
      "b9d8cae72e0f4df198cebbbf429380b5",
      "8a9cd8a4c64241168189926c36d07315",
      "40e0f90e3199497395b64cf29b43ae88",
      "1e0970fbe54f4aaf8452fc6d5702311c",
      "66307f19129649de98395eaf9b698527",
      "ac840706227f4be5b1e8db6f8fca44a6",
      "29cffe0ec8d445e0a4ab42414ed2e042",
      "c1c51ce67e2246f19d07af98ec0cd96e",
      "cb9d9695563844778861f75f9199a86e",
      "40ae7b703ec74bb88017e5c301bad63b",
      "50df19c7ba0e4b769bc777da7a1edac5",
      "487e8a4bb6d04a86a10c0d461f234cdc",
      "11a69a7e66f04822869457c970eeb7c2",
      "b527f35161fd4706841915222f9fbcc5",
      "6f7df010f1df49348b7fc1d20d7f1766",
      "204056467c5b47d18b41b9213bcca406",
      "63aa78184d4a48878773497c1874d9ec",
      "9ad083f642c8406caaf745fd21adf7b2",
      "1deefe53ce784ef58dc3f1ce64673449",
      "f7cd9469837f41f68365a3886a9c12f8",
      "54c949d962ab4fe5b0ab04278b7b783e",
      "9b8be89c98074715ae8454b6cc7a00a0",
      "e52e8d3bc4e742ac82b4d828cbe5666b",
      "3dfa0ae1406c414582ef0f1d6c3eb38f",
      "789a9ec76a574854b3ff0a1e02832330",
      "f90954332c354bfaadc2cf0df61e68d4",
      "7fb98f15160c45f1bae843c74ea8a140",
      "abb7673a29fc4d6a83e6f90ef318dd7b",
      "9ee48824624c45a181bbedf50a4c9ac5",
      "492c786d3bd84b3c8b0cad94fa05012d",
      "69fa85de372a4ff49c2c5e4f54576b47",
      "bc39be1d0fab4f979d217a39268c1ddd",
      "1521ce817f4d42cda43d5fc8bd562e96",
      "1eaef379f18240c3bef1386fa8448d36",
      "79f7c2c313c74a1c9ab6b1095b9bae5c",
      "aea311e2983e4f5185efbe0b4c071593",
      "0885f4b1a5b44108bdf79d12ad9d9f59",
      "2204f02a99644768b1e3a11a10ed2ad3",
      "b87a3e6ed6324a4495da9735dc66a3f0",
      "2f77b235ec60460c91916f6586a9ad2c",
      "70ed795c7272431ea61f2916acab8fd2",
      "10f2d6e5133d49bfa839bd9a43b3f7a4",
      "a5db1eedd3ec48b58a2879764b191feb",
      "b915fa35133042c894d58f1dd4533b2e",
      "b0e9e73fef194a57a9a4c02cedc359b5",
      "b71b6f17e08149c6a576f06e32c39c97",
      "356e84669d9e4c919fcdbfb4c4683090",
      "75ceadf8162242e6a5c93a0770571343",
      "16769e1adcf84adf9c5e55b2e032785e",
      "5ebd8511e9e34b63af3bda403dd3b0b9",
      "7bb134b5fce24e34a406f62596ba314b",
      "83f0c336d6cd4157a34f8548c61cc961",
      "1f5a196b7fda471b9196876deef2cd72",
      "79fa95395e474ac7820e3c2687f44e0e",
      "fc9799b8dfc54951bb266d3ca43cdf39",
      "320567e6c9fc4d94814b993b7a88b368",
      "dd12bf05788e4a45ae7be5b887a20971",
      "b380ceb3a945435694900d01cbef9625",
      "cccec75da7cf4c779e26c997bdba08b9",
      "0be458a528b94523809c0e3cd43d392b",
      "6a377111fc00443482861ccb2f6fc8ac",
      "b4e730eead6b495083867bd844336421",
      "246d4ab69f7d4cf9a58586e267623a0b",
      "6bc891993433403d902c46959727642b",
      "7f88407daf5b41dd9a54778e61f381ab",
      "7aec91bcbc3d41a3835e620de86b1438",
      "2d1f0fed7aec46c39e9aeeb39cc48e47",
      "fa69a97ae99647f1be808fddc5f340db",
      "f2253e0f2abb4816bedcdc1f7bcef136",
      "49aef85ce5784a308654ae47752f1f7f",
      "1aabc2ec034e4d46803ada9c55d168d2",
      "5dee259994514730a8e5a3ec6592438e",
      "55045665d1744b3baab0ec24f1b19bfc",
      "61c0de80ef2e4389b5b99c9b7c377aa6",
      "1a5a1fd02a0a474194384594601e1e08",
      "d5c989b8e26f45a283397d7e3df69806",
      "5e7c2ad92a2d487cbbb501a571a0a52e",
      "9f16fb02001f4d90a848f87e7964ead6",
      "3dec88e27487456a9967717fdfd202a9",
      "5c01596d2acc42d5876c8e0340373bb1",
      "f2dbe835520c496c8fcaa7592f75e8d9",
      "d1652a4727e54fbb9b0145d01fab3401",
      "de4aeed2cb8f431b90174c7500f8607f",
      "3500464e9ca547d88bd16bc2c1b816ac",
      "5030083273464265a815a7af489d7e97",
      "8518742742554771825dbea847fe4b1e",
      "9b90021d149f4a93a889e5ee5930905c",
      "107dff955f0d4d59ae0fcb20263e2be8",
      "53e847f55b964fe2a97228c855ab074a",
      "39bcbd73ab114fd1a19b8ba7b8037b2e",
      "4515a3e29b734a3d8a5e8bcdc1cbdcb8",
      "6cfa038ea41248a4bd982b7f50b4e155",
      "c72603af714e49e2918469428d98096b",
      "c7c2b27ac55d40ecb65daec687418b3a",
      "ad07559c19be478cbcd654512a18cd03",
      "fd313ac5a2194bc2b3f2cd90fae36992",
      "e233907f9aa1403fa1c4509c146f15de",
      "7f4a5c1f81d84731af64952fea375467",
      "8e9538bd12b54c30963f1d61aa501eb5",
      "29b582d0a8904207b52a8ec2cdf7fc6d",
      "dfde5885ffdb4ef08347abe1d2999a4f",
      "584406bb70ff4f37a23271e5ef75a6b0",
      "3fe3f9ffc9854384b8046a09208c6cbd"
     ]
    },
    "id": "wkpuoj03ndqA",
    "outputId": "4735de33-357f-4220-f23f-a85d40c53ca8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c1e53e3b0e42668947766cf0eee570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ebd49503b3343208e95d5590ef8b7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acdb03136a814e4190dc816c4d1c21a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba56decc39a4408883ef34d2b09e5eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e0f8297e27486a8e5c46aee16b0fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc415f3150e41ec8e5dcd46eae39b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effa9305219448228ad3feb7a41f16bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0f63b86c2f40e2829389b4e418c98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f3a6cfcd5a4205bdbb58c8ffe932be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219cd6f6a69d4d7caca01cec0248deff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2a41664990449aabfabece18d710ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166c0bbd38ee4a9cbeeba8b3bb6d5106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c137dc98534758a00732f4cf1d6501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4407b3a50949f2ba51da341be6c538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a952395fb04143b6deb91273bf4063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63820485b9a94d2abe8767a388055d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5cea90df4e44d4f89276a958cd41748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f636eb2335a4cfa9f546bd652ecedeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67e7dd2e9994b7bb370e0e7a1c89bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddeb695275642d086c7c809279e7ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b631e536f94d81a7426471a482ac3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13123dca2aa4136b5c6b3b2ee5aba20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad96ee2203364388896cb3852cbfbb45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59fe880968564090a7436f48d11ddedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5466ae02ea420293a09accd876a169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d02deacbf44c1097e72807077a593c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068bae6fb4ff4ae0b1abf37985f072c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87259df5888e40b193897e91ec1f1cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7588d65ce56c4764a4e49fb296e21c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affb06e5bab64989b9b1a8ba5e0ca950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66307f19129649de98395eaf9b698527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204056467c5b47d18b41b9213bcca406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb98f15160c45f1bae843c74ea8a140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2204f02a99644768b1e3a11a10ed2ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16769e1adcf84adf9c5e55b2e032785e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be458a528b94523809c0e3cd43d392b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aabc2ec034e4d46803ada9c55d168d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/54.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1652a4727e54fbb9b0145d01fab3401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:  11%|#1        | 262M/2.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72603af714e49e2918469428d98096b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GPT-3 и GPT-2\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_gpt2 = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# RoBERTa\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_RoBERTa = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# XLNet\n",
    "model_name = \"xlnet-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_XLNet = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# ALBERT\n",
    "model_name = \"albert-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_ALBERT = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# T5 (Text-to-Text Transfer Transformer)\n",
    "model_name = \"t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_T5 = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# DistilBERT\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_DistilBERT = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# BART (Bidirectional and Auto-Regressive Transformers)\n",
    "model_name = \"facebook/bart-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_BART = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# ELECTRA\n",
    "model_name = \"google/electra-small-discriminator\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_ELECTRA = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Longformer\n",
    "model_name = \"allenai/longformer-base-4096\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Longformer\n",
    "model_name = \"allenai/longformer-base-4096\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_Longformer = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# DeBERTa\n",
    "model_name = \"microsoft/deberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_DeBERTa = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# MT5 (Multilingual T5)\n",
    "model_name = \"google/mt5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_MT5 = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-vBuQjrb6Go"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtMNa2ZCb_nr"
   },
   "source": [
    "# 2. Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "bClRNRRRb94d",
    "outputId": "1462c241-38ae-4f1f-fe48-8ba86092ee82"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c801dc2af591>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Измените num_labels по задаче\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_name' is not defined"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # Измените num_labels по задаче"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FlJaFmGcCZ-"
   },
   "source": [
    "# 3. Определение расширенного набора метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pl939f1cC52"
   },
   "outputs": [],
   "source": [
    "# 3. Определение расширенного набора метрик\n",
    "metrics = {\n",
    "    \"accuracy\": load_metric(\"accuracy\"),\n",
    "    \"f1\": load_metric(\"f1\"),\n",
    "    \"precision\": load_metric(\"precision\"),\n",
    "    \"recall\": load_metric(\"recall\"),\n",
    "    \"bleu\": load_metric(\"bleu\"),\n",
    "    \"rouge\": load_metric(\"rouge\"),\n",
    "    \"meteor\": load_metric(\"meteor\"),\n",
    "    \"bertscore\": load_metric(\"bertscore\"),\n",
    "    \"perplexity\": None\n",
    "}\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    results = {}\n",
    "    for name, metric in metrics.items():\n",
    "        if metric:\n",
    "            if name == \"bertscore\":\n",
    "                results[name] = metric.compute(predictions=p.predictions, references=p.label_ids, lang=\"en\")  # BERTScore работает с текстами\n",
    "            else:\n",
    "                results[name] = metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    # Расчет Perplexity\n",
    "    if 'eval_loss' in p:\n",
    "        loss = p['eval_loss']\n",
    "        perplexity = torch.exp(torch.tensor(loss)).item()\n",
    "        results[\"perplexity\"] = perplexity\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyjwx4MGcL89"
   },
   "source": [
    "# 4. Настройка параметров тренировки, создание тренера, тренировка и оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fno6k4pFcNOr"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Оценка модели:\", eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMnDYK14cYtH"
   },
   "source": [
    "# 5. Расширенная проверка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0zRiGugccU2"
   },
   "outputs": [],
   "source": [
    "# Проверка сложности данных\n",
    "def dataset_complexity(data):\n",
    "    text_lengths = [len(tokenizer.tokenize(text)) for text in data['text']]\n",
    "    return {\n",
    "        'avg_length': np.mean(text_lengths),\n",
    "        'max_length': np.max(text_lengths),\n",
    "        'min_length': np.min(text_lengths),\n",
    "        'length_variability': np.std(text_lengths)\n",
    "    }\n",
    "\n",
    "complexity_stats = dataset_complexity(train_dataset)\n",
    "print(f\"Сложность датасета: {complexity_stats}\")\n",
    "\n",
    "# Оценка разнообразия и сбалансированности\n",
    "def dataset_balance(data, column_name):\n",
    "    return data[column_name].value_counts(normalize=True)\n",
    "\n",
    "balance_stats = dataset_balance(train_dataset, 'label')\n",
    "print(f\"Распределение классов: {balance_stats}\")\n",
    "\n",
    "# Оценка разнообразия токенов\n",
    "def token_stats(data):\n",
    "    all_tokens = [token for text in data['text'] for token in tokenizer.tokenize(text)]\n",
    "    token_counter = Counter(all_tokens)\n",
    "    return {\n",
    "        'num_unique_tokens': len(token_counter),\n",
    "        'top_10_tokens': token_counter.most_common(10)\n",
    "    }\n",
    "\n",
    "token_stats_train = token_stats(train_dataset)\n",
    "print(f\"Токенизация данных: {token_stats_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYA-L2urcg0-"
   },
   "source": [
    "## 5.1. Анализ предвзятости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zliY9DYnce-m"
   },
   "outputs": [],
   "source": [
    "bias_test_examples = [\"The doctor is a man.\", \"The nurse is a woman.\"]\n",
    "encoded_bias_test_examples = tokenizer(bias_test_examples, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# Прогнозирование на тесте предвзятости\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoded_bias_test_examples)\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    print(f\"Предсказания предвзятости: {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beXFyLqVco69"
   },
   "source": [
    "## 5.2. Проверка токсичности с использованием предобученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2P1n3FPcoBy"
   },
   "outputs": [],
   "source": [
    "toxicity_classifier = pipeline('text-classification', model='unitary/toxic-bert')\n",
    "\n",
    "test_texts = [\"I hate you!\", \"You're amazing!\"]\n",
    "toxicity_results = toxicity_classifier(test_texts)\n",
    "print(f\"Результаты токсичности: {toxicity_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGYVObj1csnp"
   },
   "source": [
    "## 5.3. Оценка логической согласованности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEV8uVPbcrzk"
   },
   "outputs": [],
   "source": [
    "generation_pipeline = pipeline(\"text-generation\", model=model_name)\n",
    "generation_result = generation_pipeline(\"Once upon a time, in a land far away,\", max_length=50)\n",
    "print(\"Сгенерированный текст:\", generation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrAk6b4-cykX"
   },
   "source": [
    "## 5.4. Пост-обработка: анализ ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKtEonpmcx__"
   },
   "outputs": [],
   "source": [
    "def error_analysis(predictions, labels, data):\n",
    "    errors = []\n",
    "    for i, (pred, label) in enumerate(zip(predictions, labels)):\n",
    "        if pred != label:\n",
    "            errors.append({\n",
    "                'text': data['text'][i],\n",
    "                'predicted': pred,\n",
    "                'actual': label\n",
    "            })\n",
    "    return errors\n",
    "\n",
    "# Анализ ошибок модели\n",
    "predictions = np.argmax(trainer.predict(test_dataset).predictions, axis=1)\n",
    "errors = error_analysis(predictions, test_dataset['label'], test_dataset)\n",
    "print(f\"Ошибки: {errors[:5]}\")  # Первые 5 ошибок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dd0gnYoxGgga"
   },
   "source": [
    "## 5.5. Семантическая оценка данных (Semantic Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QnratDj2GZ7k"
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def semantic_diversity(data, sample_size=100):\n",
    "    sample_texts = data['text'][:sample_size]\n",
    "    embeddings = model.encode(sample_texts)\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "    avg_similarity = similarity_matrix.mean()\n",
    "    max_similarity = similarity_matrix.max()\n",
    "\n",
    "    return avg_similarity, max_similarity\n",
    "\n",
    "avg_sim, max_sim = semantic_diversity(train_dataset)\n",
    "print(f\"Среднее семантическое сходство: {avg_sim}, Максимальное семантическое сходство: {max_sim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwaC0eLqHCCc"
   },
   "source": [
    "## 5.6. Проверка дублирования на уровне смысла:\n",
    "- Помимо текстовых дубликатов, полезно найти дубликаты на уровне смысла (семантические дубликаты). Для этого можно использовать модели, такие как Sentence-BERT, чтобы сравнивать предложения с помощью их эмбеддингов.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMQFEOC8HEjJ"
   },
   "outputs": [],
   "source": [
    "def find_semantic_duplicates(data, threshold=0.9):\n",
    "    embeddings = model.encode(data['text'])\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "    duplicate_pairs = []\n",
    "    for i in range(len(similarity_matrix)):\n",
    "        for j in range(i+1, len(similarity_matrix)):\n",
    "            if similarity_matrix[i, j] > threshold:\n",
    "                duplicate_pairs.append((i, j))\n",
    "\n",
    "    return duplicate_pairs\n",
    "\n",
    "sem_duplicates = find_semantic_duplicates(train_dataset, threshold=0.9)\n",
    "print(f\"Найдено семантических дубликатов: {len(sem_duplicates)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YijtMeC6HIGz"
   },
   "source": [
    "## 5.7. Анализ редкости (Rarity Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pha_-YIbHMXD"
   },
   "outputs": [],
   "source": [
    "def rare_tokens_analysis(data, threshold=5):\n",
    "    token_counts = Counter([token for text in data['text'] for token in tokenizer.tokenize(text)])\n",
    "    rare_tokens = {token: count for token, count in token_counts.items() if count < threshold}\n",
    "    return rare_tokens\n",
    "\n",
    "rare_tokens = rare_tokens_analysis(train_dataset)\n",
    "print(f\"Редкие токены (встречаются меньше {threshold} раз): {len(rare_tokens)}\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def named_entity_analysis(data):\n",
    "    entity_counts = Counter()\n",
    "    for text in data['text']:\n",
    "        doc = nlp(text)\n",
    "        for ent in doc.ents:\n",
    "            entity_counts[ent.text] += 1\n",
    "    return entity_counts\n",
    "\n",
    "entity_stats = named_entity_analysis(train_dataset)\n",
    "print(f\"Самые частые сущности: {entity_stats.most_common(10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DwtlSGkJMBP"
   },
   "source": [
    "## 5.8. Оценка контекстуальной сложности (Contextual Complexity Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E72aiLIFJYkr"
   },
   "outputs": [],
   "source": [
    "def syntactic_complexity(text):\n",
    "    doc = nlp(text)\n",
    "    avg_depth = sum([token.dep_ for token in doc]) / len(doc)\n",
    "    return avg_depth\n",
    "\n",
    "complexity_scores = [syntactic_complexity(text) for text in dataset['text']]\n",
    "print(f\"Средняя синтаксическая сложность: {np.mean(complexity_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YH4iKjGTJzVP"
   },
   "source": [
    "## 5.9. Оценка когерентности данных (Data Coherence Evaluation)\n",
    "\n",
    "- Когерентность текста может быть проверена через анализ плавности переходов между предложениями. Для этого можно использовать эмбеддинги предложений и оценить их плавность с точки зрения сходства."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kgqoMz-J24I"
   },
   "outputs": [],
   "source": [
    "def coherence_score(data, sample_size=100):\n",
    "    sample_texts = data['text'][:sample_size]\n",
    "    coherence_scores = []\n",
    "\n",
    "    for text in sample_texts:\n",
    "        sentences = text.split('. ')\n",
    "        if len(sentences) > 1:\n",
    "            sentence_embeddings = model.encode(sentences)\n",
    "            sentence_similarities = cosine_similarity(sentence_embeddings)\n",
    "            coherence_scores.append(sentence_similarities.mean())\n",
    "\n",
    "    return np.mean(coherence_scores)\n",
    "\n",
    "avg_coherence = coherence_score(train_dataset)\n",
    "print(f\"Средняя когерентность текстов: {avg_coherence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlCuBSCjJ7Ox"
   },
   "source": [
    "## 5.10. Проверка на нелогичные данные (Inconsistency Detection)\n",
    "- Обнаружение противоречий в данных: Модель может страдать от низкого качества обучения, если в датасете содержатся противоречивые данные (например, противоречивые метки для одного и того же текста). Это можно выявить через кластеризацию текстов и проверку меток."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VcZ7Q4eyJ8Yu"
   },
   "outputs": [],
   "source": [
    "def inconsistency_detection(data, num_clusters=10):\n",
    "    embeddings = model.encode(data['text'])\n",
    "    kmeans = KMeans(n_clusters=num_clusters)\n",
    "    clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "    inconsistencies = []\n",
    "    for i in range(num_clusters):\n",
    "        cluster_texts = [data['text'][j] for j in range(len(data['text'])) if clusters[j] == i]\n",
    "        cluster_labels = [data['label'][j] for j in range(len(data['label'])) if clusters[j] == i]\n",
    "        if len(set(cluster_labels)) > 1:  # Если в кластере есть несколько меток\n",
    "            inconsistencies.append((cluster_texts, cluster_labels))\n",
    "\n",
    "    return inconsistencies\n",
    "\n",
    "inconsistencies = inconsistency_detection(train_dataset)\n",
    "print(f\"Найдено {len(inconsistencies)} кластеров с противоречивыми метками.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9luGz0wNsG4"
   },
   "source": [
    "## 5.11. Проверка на нелогичные данные (Inconsistency Detection)\n",
    "\n",
    "  - Обнаружение противоречий в данных: Модель может страдать от низкого качества обучения, если в датасете содержатся противоречивые данные (например, противоречивые метки для одного и того же текста). Это можно выявить через кластеризацию текстов и проверку меток."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2Iz9mPoN3DG"
   },
   "outputs": [],
   "source": [
    "def inconsistency_detection(data, num_clusters=10):\n",
    "    embeddings = model.encode(data['text'])\n",
    "    kmeans = KMeans(n_clusters=num_clusters)\n",
    "    clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "    inconsistencies = []\n",
    "    for i in range(num_clusters):\n",
    "        cluster_texts = [data['text'][j] for j in range(len(data['text'])) if clusters[j] == i]\n",
    "        cluster_labels = [data['label'][j] for j in range(len(data['label'])) if clusters[j] == i]\n",
    "        if len(set(cluster_labels)) > 1:\n",
    "            inconsistencies.append((cluster_texts, cluster_labels))\n",
    "\n",
    "    return inconsistencies\n",
    "\n",
    "inconsistencies = inconsistency_detection(train_dataset)\n",
    "print(f\"Найдено {len(inconsistencies)} кластеров с противоречивыми метками.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKaS4sflOAHJ"
   },
   "source": [
    "## 5.12. Оценка справедливости данных (Fairness Assessment)\n",
    "\n",
    "- Проверка демографической справедливости: Если ваш датасет содержит информацию о пользователях, полезно проверить справедливость модели в зависимости от их демографических характеристик (пол, возраст, этническая принадлежность и т.д.). Это может быть выполнено через анализ распределения меток и точности модели в зависимости от демографических данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P94DWqgeN3BE"
   },
   "outputs": [],
   "source": [
    "def demographic_fairness(data, demographic_column):\n",
    "    distribution = data[demographic_column].value_counts()\n",
    "    return distribution\n",
    "\n",
    "fairness_stats = demographic_fairness(train_dataset, 'gender')  # Замените 'gender' на нужную колонку\n",
    "print(f\"Распределение по полу: {fairness_stats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IP5DoUldOPAP"
   },
   "source": [
    "## 5.13. Оценка задачи на многоязычность (Multilingual Task Evaluation)\n",
    "\n",
    "- Если модель должна поддерживать многоязычные задачи, важно проверить, как распределены языки в датасете и как модель работает с каждым языком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5aVT3mYN2_a"
   },
   "outputs": [],
   "source": [
    "def language_performance_analysis(data):\n",
    "    languages = [detect(text) for text in data['text']]\n",
    "    language_counts = Counter(languages)\n",
    "\n",
    "    return language_counts\n",
    "\n",
    "language_stats = language_performance_analysis(train_dataset)\n",
    "print(f\"Распределение по языкам: {language_stats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndIKsa_kOYzA"
   },
   "source": [
    "## 5.14. Оценка устойчивости модели (Robustness Testing)\n",
    "\n",
    "- Добавление шумов и искажений: Полезно проверить устойчивость модели к шуму, таким как опечатки, незначительные изменения в тексте или случайные вставки. Это поможет понять, как модель справляется с реальными данными, которые могут содержать ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJNP1QB4Ohcp"
   },
   "outputs": [],
   "source": [
    "\n",
    "def introduce_noise(text):\n",
    "    words = text.split()\n",
    "    index = randint(0, len(words) - 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5X45-HjXet9"
   },
   "source": [
    "Генерация синтетики\n",
    "Модели двойного перевода\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZu7DhqFo_FR"
   },
   "source": [
    "## 5.15. Тестирование устойчивости к небольшим изменениям (Perturbation Testing)\n",
    "- Для проверки того, как модель реагирует на небольшие изменения в тексте (перестановки слов, опечатки и т.д.), можно использовать так называемые тесты на устойчивость к возмущениям (perturbation testing). Они помогают выявить слабые места модели, связанные с чрезмерной чувствительностью к небольшим изменениям в данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HEE4sSPPXhA1"
   },
   "outputs": [],
   "source": [
    "def introduce_typo(text):\n",
    "    words = text.split()\n",
    "    index = randint(0, len(words) - 1)\n",
    "    typo_word = words[index]\n",
    "    typo_word = typo_word[:-1] + typo_word[-1].upper()\n",
    "    words[index] = typo_word\n",
    "    return \" \".join(words)\n",
    "\n",
    "perturbed_texts = [introduce_typo(text) for text in dataset['text'][:10]]\n",
    "perturbed_responses = [model.generate(tokenizer.encode(text, return_tensors=\"pt\")) for text in perturbed_texts]\n",
    "print(perturbed_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwRMQt_opJ68"
   },
   "source": [
    "## 5.16. Оценка генеративных возможностей (Generation Evaluation)\n",
    "- Один из важнейших показателей генеративных моделей — их способность генерировать разнообразные тексты. Можно проверить, насколько разные тексты модель генерирует для одного и того же запроса. Для этого можно использовать такие метрики, как distinct или diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7uXJhH59pPcv"
   },
   "outputs": [],
   "source": [
    "def evaluate_diversity(generated_texts):\n",
    "    unigrams = set()\n",
    "    bigrams = set()\n",
    "    for text in generated_texts:\n",
    "        tokens = text.split()\n",
    "        unigrams.update(tokens)\n",
    "        bigrams.update(zip(tokens[:-1], tokens[1:]))\n",
    "\n",
    "    distinct_1 = len(unigrams) / len(generated_texts)\n",
    "    distinct_2 = len(bigrams) / len(generated_texts)\n",
    "\n",
    "    return distinct_1, distinct_2\n",
    "\n",
    "prompt = \"Once upon a time in a faraway land,\"\n",
    "generated_texts = [model.generate(tokenizer.encode(prompt, return_tensors=\"pt\"), max_length=50) for _ in range(10)]\n",
    "distinct_1, distinct_2 = evaluate_diversity(generated_texts)\n",
    "print(f\"Distinct-1: {distinct_1}, Distinct-2: {distinct_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kytoy7P6pWpl"
   },
   "source": [
    "## 5.17. Оценка запутанности (Ambiguity Detection)\n",
    "- Важный тест — это проверка на наличие в данных неоднозначных текстов, которые могут быть интерпретированы по-разному. Такие тексты могут приводить к сбоям в обучении и оценке модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIo7-aicpai5"
   },
   "outputs": [],
   "source": [
    "def detect_ambiguous_texts(data, n_clusters=10):\n",
    "    embeddings = model.encode(data['text'])\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "    ambiguous_texts = []\n",
    "    for i in range(n_clusters):\n",
    "        cluster_texts = [data['text'][j] for j in range(len(data['text'])) if clusters[j] == i]\n",
    "        if len(cluster_texts) > 1:\n",
    "            ambiguous_texts.append(cluster_texts)\n",
    "\n",
    "    return ambiguous_texts\n",
    "\n",
    "ambiguous_clusters = detect_ambiguous_texts(train_dataset)\n",
    "print(f\"Найдено {len(ambiguous_clusters)} неоднозначных кластеров.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjZwrigtp5zD"
   },
   "source": [
    "# 6. Генерация синтетических данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iX1ig8-cq6HM"
   },
   "source": [
    "## 6.1. T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSBUA2GNp-PP"
   },
   "outputs": [],
   "source": [
    "model_name = 't5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "def generate_t5(prompt):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    output = model.generate(input_ids, max_length=100)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "prompt = \"сгенерируй текст: \"\n",
    "print(generate_t5(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7Sk2v0ZrEWP"
   },
   "source": [
    "## 6.2. BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11nCAVlSrF85"
   },
   "outputs": [],
   "source": [
    "model_name = 'facebook/bart-large'\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "def generate_bart(prompt):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    output = model.generate(input_ids, max_length=100)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "prompt = \"Начало нового путешествия: \"\n",
    "print(generate_bart(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xI6zgz-PrSTw"
   },
   "source": [
    "## 6.3. XLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAP_gJJ_rU-N"
   },
   "outputs": [],
   "source": [
    "model_name = 'xlnet-base-cased'\n",
    "tokenizer = XLNetTokenizer.from_pretrained(model_name)\n",
    "model = XLNetLMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "def generate_xlnet(prompt):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    output = model.generate(input_ids, max_length=100)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "prompt = \"Завтра будет \"\n",
    "print(generate_xlnet(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NXmJPa2ras3"
   },
   "source": [
    "## 6.4. CTRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTcafE6creE6"
   },
   "outputs": [],
   "source": [
    "from transformers import CTRLTokenizer, CTRLForCausalLM\n",
    "\n",
    "model_name = 'ctrl'\n",
    "tokenizer = CTRLTokenizer.from_pretrained(model_name)\n",
    "model = CTRLForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "def generate_ctrl(prompt):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    output = model.generate(input_ids, max_length=100)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Пример использования\n",
    "prompt = \""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
